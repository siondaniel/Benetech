{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport json\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50\nfrom torch.utils.data import Dataset\n\nfrom transformers import AutoProcessor, Pix2StructConfig, Pix2StructForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:09.003942Z","iopub.execute_input":"2023-06-08T01:24:09.004287Z","iopub.status.idle":"2023-06-08T01:24:34.902734Z","shell.execute_reply.started":"2023-06-08T01:24:09.004260Z","shell.execute_reply":"2023-06-08T01:24:34.901744Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CNN to Classify Graph:","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path, target_size=(224, 224)):\n    img = cv2.imread(image_path)\n    # Check if the image is grayscale then convert to color\n    if len(img.shape) == 2:\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = Image.fromarray(img)\n    img = img.resize(target_size)\n\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:34.904489Z","iopub.execute_input":"2023-06-08T01:24:34.904847Z","iopub.status.idle":"2023-06-08T01:24:34.910776Z","shell.execute_reply.started":"2023-06-08T01:24:34.904813Z","shell.execute_reply":"2023-06-08T01:24:34.909886Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def pil_to_tensor(img):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(img)\n\ndef show_image(img):\n    plt.imshow(img)\n    plt.axis('off')  # remove axes for visual appeal\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:34.912187Z","iopub.execute_input":"2023-06-08T01:24:34.912790Z","iopub.status.idle":"2023-06-08T01:24:34.924312Z","shell.execute_reply.started":"2023-06-08T01:24:34.912755Z","shell.execute_reply":"2023-06-08T01:24:34.923502Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# image_path = '/kaggle/input/benetech-making-graphs-accessible/test/images/007a18eb4e09.jpg'\n# img = preprocess_image(image_path)\n# tensor = pil_to_tensor(img)\n# show_image(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:34.927039Z","iopub.execute_input":"2023-06-08T01:24:34.927504Z","iopub.status.idle":"2023-06-08T01:24:34.937307Z","shell.execute_reply.started":"2023-06-08T01:24:34.927474Z","shell.execute_reply":"2023-06-08T01:24:34.936227Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"chart_type_list = ['dot', 'horizontal_bar', 'vertical_bar', 'line', 'scatter']\ndef get_chart_type(json_path):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    if data[\"chart-type\"] in chart_type_list:\n        return data[\"chart-type\"]\n    else:\n        print(\"Invalid chart type in the JSON file. Using default chart type.\")\n        return chart_type_list[3]","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:34.939255Z","iopub.execute_input":"2023-06-08T01:24:34.939737Z","iopub.status.idle":"2023-06-08T01:24:34.951623Z","shell.execute_reply.started":"2023-06-08T01:24:34.939702Z","shell.execute_reply":"2023-06-08T01:24:34.950489Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Get data points from training annotations\ndef get_chart_data(json_path):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    data_series = data[\"data-series\"]\n    x_preds = []\n    y_preds = []\n\n    for item in data_series:\n        x_preds.append(item['x'])\n        y_preds.append(item['y'])\n    \n    return x_preds, y_preds","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:34.953481Z","iopub.execute_input":"2023-06-08T01:24:34.953906Z","iopub.status.idle":"2023-06-08T01:24:34.963521Z","shell.execute_reply.started":"2023-06-08T01:24:34.953861Z","shell.execute_reply":"2023-06-08T01:24:34.962591Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class GraphDataset(Dataset):\n    def __init__(self, image_dir, json_dir, transform=None):\n        self.image_dir = image_dir\n        self.json_dir = json_dir\n        self.transform = transform\n        \n        self.image_files = os.listdir(image_dir)\n        self.json_files = [f\"{name.split('.')[0]}.json\" for name in self.image_files]\n\n        # assuming that chart types are 'dot', 'horizontal_bar', 'vertical_bar', 'line', 'scatter'\n        self.classes = ['dot', 'horizontal_bar', 'vertical_bar', 'line', 'scatter']\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_file = self.image_files[idx]\n        json_file = self.json_files[idx]\n        \n        # Process image\n        image = preprocess_image(os.path.join(self.image_dir, image_file))\n        if self.transform:\n            image = self.transform(image)\n\n        # Process json\n        chart_type = get_chart_type(os.path.join(self.json_dir, json_file))\n        x_preds, y_preds = get_chart_data(os.path.join(self.json_dir, json_file))\n        \n        max_data_length = 20\n        x_preds = self.pad_or_truncate(x_preds, max_data_length)\n        y_preds = self.pad_or_truncate(y_preds, max_data_length)\n\n        # chart_data = (x_preds, y_preds)\n        \n        # Convert chart type to an integer\n        label = self.classes.index(chart_type)\n\n        return os.path.join(self.json_dir, json_file), image, label, (x_preds, y_preds)\n\n    def pad_or_truncate(self, data, max_length):\n        if len(data) < max_length:\n            data = data + [0] * (max_length - len(data))  # Pad with zeros\n        elif len(data) > max_length:\n            data = data[:max_length]  # Truncate to max_length\n        return data\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:31:06.725260Z","iopub.execute_input":"2023-06-08T01:31:06.725665Z","iopub.status.idle":"2023-06-08T01:31:06.738310Z","shell.execute_reply.started":"2023-06-08T01:31:06.725636Z","shell.execute_reply":"2023-06-08T01:31:06.736969Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# DATA LOADER\nfrom torch.utils.data import Subset\nfrom torch.utils.data import random_split\n\n# Define the transformation\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n# Load your dataset\nfolder_path = '/kaggle/input/benetech-making-graphs-accessible/train/images/'\n\n# Get the list of items in the folder\nitems = os.listdir(folder_path)\nnum_samples = int(len(items)/4)\ndataset = GraphDataset(folder_path, '/kaggle/input/benetech-making-graphs-accessible/train/annotations/', transform=transform)\nsubset = Subset(dataset, torch.arange(num_samples))\n#subset = Subset(dataset, torch.arange(len(dataset)))\n\n# Define the proportion for the split\ntrain_proportion = 0.8  # e.g., 80% training, 20% validation\nn_train = int(len(subset)*train_proportion)\nn_val = len(subset) - n_train\n\n# Perform the split\ntrain_dataset, val_dataset = random_split(subset, [n_train, n_val])\n\n# Create data loaders\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:42:16.063912Z","iopub.execute_input":"2023-06-08T01:42:16.064850Z","iopub.status.idle":"2023-06-08T01:42:16.152795Z","shell.execute_reply.started":"2023-06-08T01:42:16.064814Z","shell.execute_reply":"2023-06-08T01:42:16.151781Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:35.872565Z","iopub.execute_input":"2023-06-08T01:24:35.872940Z","iopub.status.idle":"2023-06-08T01:24:35.941844Z","shell.execute_reply.started":"2023-06-08T01:24:35.872904Z","shell.execute_reply":"2023-06-08T01:24:35.940776Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the pretrained model if it exists\nif os.path.exists('/kaggle/input/resnet50/resnet50.bin'):\n    model = torch.load('/kaggle/input/resnet50/resnet50.bin').to(device)\nelse:\n    model = resnet50(weights='DEFAULT')\n    num_features = model.fc.in_features\n    num_charts = 5\n    model.fc = torch.nn.Linear(num_features, num_charts)  # replace num_classes with the number of your classes\n\n    # Define the loss function and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    # Train the model\n    num_epochs = 10\n    model = model.to(device)\n\n    print(\"Starting training:\")\n    for epoch in range(num_epochs):\n        for i, (_, inputs, labels, _) in enumerate(train_dataloader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:35.947377Z","iopub.execute_input":"2023-06-08T01:24:35.948013Z","iopub.status.idle":"2023-06-08T01:24:45.612994Z","shell.execute_reply.started":"2023-06-08T01:24:35.947979Z","shell.execute_reply":"2023-06-08T01:24:45.611991Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# model.eval()  # ensure the model is in evaluation mode\n# with torch.no_grad():\n#     correct = 0\n#     total = 0\n#     for _, inputs, labels, _ in val_dataloader:\n#         inputs = inputs.to(device)\n#         labels = labels.to(device)\n#         outputs = model(inputs)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n#     print(f'Accuracy of the model on the validation images: {100 * correct / total}%')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:45.614281Z","iopub.execute_input":"2023-06-08T01:24:45.614650Z","iopub.status.idle":"2023-06-08T01:24:45.619764Z","shell.execute_reply.started":"2023-06-08T01:24:45.614617Z","shell.execute_reply":"2023-06-08T01:24:45.618831Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Save the model if it doesn't exist\n# if not os.path.exists('/kaggle/working/resnet50'):\n#     torch.save(model, '/kaggle/working/resnet50')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:45.621074Z","iopub.execute_input":"2023-06-08T01:24:45.622026Z","iopub.status.idle":"2023-06-08T01:24:45.632578Z","shell.execute_reply.started":"2023-06-08T01:24:45.621988Z","shell.execute_reply":"2023-06-08T01:24:45.631390Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Load DePlot Model","metadata":{}},{"cell_type":"code","source":"# if deplot model exists, load it\nif os.path.exists('/kaggle/input/googledeplot') and os.path.exists('/kaggle/input/deplot-processor'):\n    print(\"Deplot Model Exists\")\n    deplot_model = Pix2StructForConditionalGeneration.from_pretrained('/kaggle/input/googledeplot').to(device)\n    processor = AutoProcessor.from_pretrained(\"/kaggle/input/deplot-processor\")\nelse:\n    deplot_model = Pix2StructForConditionalGeneration.from_pretrained(\"google/deplot\").to(device)\n    processor = AutoProcessor.from_pretrained(\"google/deplot\")\n    # Save the model if it doesn't exist\n    deplot_model.save_pretrained('/kaggle/working/deplot_model.bin')\n    processor.save_pretrained('/kaggle/working/deplot_processor.bin')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:33:03.766476Z","iopub.execute_input":"2023-06-08T01:33:03.766882Z","iopub.status.idle":"2023-06-08T01:33:07.128113Z","shell.execute_reply.started":"2023-06-08T01:33:03.766847Z","shell.execute_reply":"2023-06-08T01:33:07.127110Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Deplot Model Exists\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test model on an image\n# image = Image.open('/kaggle/input/benetech-making-graphs-accessible/test/images/01b45b831589.jpg')\n# inputs = processor(images=image, text=\"Generate underlying data table of the figure below:\", font_path=\"/kaggle/input/arial-font/arial.ttf\", return_tensors=\"pt\").to(device)\n# predictions = deplot_model.generate(**inputs, max_new_tokens=512)\n# print(processor.decode(predictions[0], skip_special_tokens=True))\n# show_image(image)\n\n# deplot_model.save_pretrained('/kaggle/working/deplot_model.bin')\n# processor.save_pretrained('/kaggle/working/deplot_processor.bin')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.396202Z","iopub.execute_input":"2023-06-08T01:24:59.396608Z","iopub.status.idle":"2023-06-08T01:24:59.401605Z","shell.execute_reply.started":"2023-06-08T01:24:59.396570Z","shell.execute_reply":"2023-06-08T01:24:59.400615Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Run Data-Series on Validation","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# import pandas as pd\n# from rapidfuzz.distance.Levenshtein import distance as levenshtein\n# from sklearn.metrics import r2_score\n\n# def sigmoid(x):\n#     return 2 - 2 / (1 + np.exp(-x))\n\n\n# def normalized_rmse(y_true, y_pred):\n#     # The argument to the sigmoid transform is equal to \n#     # rmse(y_true, y_pred) / rmse(y_true, np.mean(y_true))\n#     return sigmoid((1 - r2_score(y_true, y_pred)) ** 0.5)\n\n\n# def normalized_levenshtein_score(y_true, y_pred):\n#     total_distance = np.sum([levenshtein(yt, yp) for yt, yp in zip(y_true, y_pred)])\n#     length_sum = np.sum([len(yt) for yt in y_true])\n#     return sigmoid(total_distance / length_sum)\n\n\n# def score_series(y_true, y_pred):\n#     if len(y_true) != len(y_pred):\n#         return 0.0\n#     if isinstance(y_true[0], str):\n#         return normalized_levenshtein_score(y_true, y_pred)\n#     else:\n#         return normalized_rmse(y_true, y_pred)\n\n\n# def benetech_score(ground_truth: pd.DataFrame, predictions: pd.DataFrame) -> float:\n#     \"\"\"Evaluate predictions using the metric from the Benetech - Making Graphs Accessible.\n    \n#     Parameters\n#     ----------\n#     ground_truth: pd.DataFrame\n#         Has columns `[data_series, chart_type]` and an index `id`. Values in `data_series` \n#         should be either arrays of floats or arrays of strings.\n    \n#     predictions: pd.DataFrame\n#     \"\"\"\n#     if not ground_truth.index.equals(predictions.index):\n#         raise ValueError(\"Must have exactly one prediction for each ground-truth instance.\")\n#     if not ground_truth.columns.equals(predictions.columns):\n#         raise ValueError(f\"Predictions must have columns: {ground_truth.columns}.\")\n#     pairs = zip(ground_truth.itertuples(index=False), predictions.itertuples(index=False))\n#     scores = []\n#     for (gt_series, gt_type), (pred_series, pred_type) in pairs:\n#         if gt_type != pred_type:  # Check chart_type condition\n#             scores.append(0.0)\n#         else:  # Score with RMSE or Levenshtein as appropriate\n#             scores.append(score_series(gt_series, pred_series))\n#     return np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.403701Z","iopub.execute_input":"2023-06-08T01:24:59.404552Z","iopub.status.idle":"2023-06-08T01:24:59.420625Z","shell.execute_reply.started":"2023-06-08T01:24:59.404513Z","shell.execute_reply":"2023-06-08T01:24:59.419717Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# ground_truth = pd.DataFrame.from_dict({\n#     '0a0a0_x': (['abc', 'def', 'ghi'], 'vertical_bar'),\n#     '0a0a0_y': ([0, 1, 2], 'vertical_bar'),\n#     '1b1b1_x': ([101.24, 90.3, 50.51], 'scatter'),\n#     '1b1b1_y': ([43.81, 10.12, 11.0], 'scatter'),\n# }, orient='index', columns=['data_series', 'chart_type']).rename_axis('id')\n\n# predictions = pd.DataFrame.from_dict({\n#     '0a0a0_x': (['a', 'difd', 'ghi'], 'vertical_bar'),\n#     '0a0a0_y': ([0.2, 0.9, 2.1], 'vertical_bar'),\n#     '1b1b1_x': ([101.24, 90.3, 50.51], 'dot'),  # wrong chart_type\n#     '1b1b1_y': ([43.81, 10.12, 11.0, 5.4], 'scatter'),  # wrong number of values in data_series\n# }, orient='index', columns=['data_series', 'chart_type']).rename_axis('id')\n\n# benetech_score(ground_truth, predictions)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.421943Z","iopub.execute_input":"2023-06-08T01:24:59.422462Z","iopub.status.idle":"2023-06-08T01:24:59.442660Z","shell.execute_reply.started":"2023-06-08T01:24:59.422417Z","shell.execute_reply":"2023-06-08T01:24:59.441684Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# display(ground_truth)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.444268Z","iopub.execute_input":"2023-06-08T01:24:59.444787Z","iopub.status.idle":"2023-06-08T01:24:59.457086Z","shell.execute_reply.started":"2023-06-08T01:24:59.444756Z","shell.execute_reply":"2023-06-08T01:24:59.456143Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# # Create ground_truth data frame based on validation set\n# val_ground_truth_data = {}\n\n# for idx, (json_files, inputs, labels) in enumerate(val_dataloader):\n#     batch_size = inputs.size(0)  # Get the batch size\n    \n#     for i in range(batch_size):\n#         json_file = json_files[i]\n#         json_filename = os.path.basename(json_file)\n\n#         # Process json\n#         chart_type = get_chart_type(json_file)\n#         chart_data = get_chart_data(json_file)\n#         key = json_filename[:-5]  # Remove the file extension from the json filename\n\n#         val_ground_truth_data[key + \"_x\"] = (chart_data[0], chart_type)\n#         val_ground_truth_data[key + \"_y\"] = (chart_data[1], chart_type)\n\n# val_ground_truth = pd.DataFrame.from_dict(val_ground_truth_data, orient='index', columns=['data_series', 'chart_type']).rename_axis('id')","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.458203Z","iopub.execute_input":"2023-06-08T01:24:59.458495Z","iopub.status.idle":"2023-06-08T01:24:59.467388Z","shell.execute_reply.started":"2023-06-08T01:24:59.458460Z","shell.execute_reply":"2023-06-08T01:24:59.466545Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# display(val_ground_truth)\n\n# print(val_ground_truth.index)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:24:59.468701Z","iopub.execute_input":"2023-06-08T01:24:59.469035Z","iopub.status.idle":"2023-06-08T01:24:59.478701Z","shell.execute_reply.started":"2023-06-08T01:24:59.469003Z","shell.execute_reply":"2023-06-08T01:24:59.477772Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def predict_graph_type(image_path):\n    # Load and preprocess the input image\n    image = Image.open(image_path).convert('RGB')\n    input_tensor = transform(image)\n    input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension\n\n    # Move the input tensor to the device\n    input_tensor = input_tensor.to(device)\n\n    # Perform inference\n    with torch.no_grad():\n        output = model(input_tensor)\n\n    # Get the predicted class index\n    _, predicted_idx = torch.max(output, 1)\n    predicted_label = predicted_idx.item()\n\n    return predicted_label","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:33:13.579662Z","iopub.execute_input":"2023-06-08T01:33:13.580110Z","iopub.status.idle":"2023-06-08T01:33:13.588305Z","shell.execute_reply.started":"2023-06-08T01:33:13.580078Z","shell.execute_reply":"2023-06-08T01:33:13.587225Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def is_valid_value(value):\n    invalid_values = [\"nan\", \"-inf\", \"inf\"]\n    if value.startswith(\"<0x\"):\n        return False\n    elif value in invalid_values:\n        return False\n    else:\n        return True","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:33:15.542695Z","iopub.execute_input":"2023-06-08T01:33:15.543048Z","iopub.status.idle":"2023-06-08T01:33:15.548212Z","shell.execute_reply.started":"2023-06-08T01:33:15.543020Z","shell.execute_reply":"2023-06-08T01:33:15.547149Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Function to convert DePlot (predictions[0], skip_special_tokens=True) to useable data\ndef deplot_to_data(data, filename, train=True):\n    # Split the 'data' string into separate lines\n    lines = data.split(\"<0x0A>\")\n    # print(lines)\n\n    # Remove the first line (headers)\n    header = lines[0]\n    lines = lines[2:]\n\n    # Initialize lists to store the data\n    x_preds = []\n    y_preds = []\n\n\n    # Process each line to extract the required information\n    for line in lines:\n        # Skip empty lines\n        if not line:\n            x_preds = [0]\n            y_preds = [0]\n            continue\n\n        # Split the line by '|' and remove leading/trailing whitespaces\n        parts = [part.strip() for part in line.split(\"|\")]\n        \n        # Skip lines where the number of parts is not equal to 2\n        if len(parts) < 2:\n            continue\n            \n        # Replace invalid values with '0'\n        x_pred = parts[0] if is_valid_value(parts[0]) else '0'\n        y_pred = parts[1] if is_valid_value(parts[1]) else '0'\n\n        # Add the values to the corresponding lists\n        x_preds.append[x_pred]\n        y_preds.append[y_pred]\n            \n    if x_preds == []:\n        x_preds = [0]\n    if y_preds == []:\n        y_preds = [0]\n\n    return x_preds, y_preds","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:33:17.696654Z","iopub.execute_input":"2023-06-08T01:33:17.697025Z","iopub.status.idle":"2023-06-08T01:33:17.707105Z","shell.execute_reply.started":"2023-06-08T01:33:17.696997Z","shell.execute_reply":"2023-06-08T01:33:17.706098Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Define the optimizer and loss function\noptimizer = torch.optim.Adam(deplot_model.parameters(), lr=0.001)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# Training loop\nnum_epochs = 10\n\nprint(\"Starting training:\")\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    print(f\"Epoch {epoch+1}\")\n    for _, inputs, _, (x_preds, y_preds) in train_dataloader:\n        # Move inputs and labels to device\n        inputs = inputs.to(device)\n        print(x_preds)\n        \n        \n\n        # Convert x_preds and y_preds to tensors\n        x_preds = [torch.tensor(x, dtype=torch.float64).to(device) for x in x_preds]\n        y_preds = [torch.tensor(y, dtype=torch.float64).to(device) for y in y_preds]\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        inputs = processor(images=image, text=\"Generate underlying data table of the figure below:\", font_path=\"/kaggle/input/arial-font/arial.ttf\", return_tensors=\"pt\").to(device)\n        predictions = deplot_model.generate(**inputs, max_new_tokens=512)\n        data = processor.decode(predictions[0], skip_special_tokens=True)\n        \n        new_x_preds, new_y_preds = deplot_to_csv(data)\n        new_x_preds = torch.tensor(new_x_preds, dtype=torch.float64).to(device)\n        new_y_preds = torch.tensor(new_y_preds, dtype=torch.float64).to(device)\n        \n        loss = criterion((x_preds, y_preds), chart_data)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n\n        # Accumulate loss\n        running_loss += loss.item()\n\n    # Print epoch statistics\n    epoch_loss = running_loss / len(train_dataloader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\")\n\n# Save the trained model\nmodel_path = \"/kaggle/working/deplot.bin\"\ntorch.save(deplot_model.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T02:13:28.657326Z","iopub.execute_input":"2023-06-08T02:13:28.657924Z","iopub.status.idle":"2023-06-08T02:13:29.842602Z","shell.execute_reply.started":"2023-06-08T02:13:28.657892Z","shell.execute_reply":"2023-06-08T02:13:29.840412Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Starting training:\nEpoch 1\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[79], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, inputs, _, (x_preds, y_preds) \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Move inputs and labels to device\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x_preds)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[77], line 36\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m     y_preds_encoded \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(y_preds)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x_preds[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_preds[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[0;32m---> 36\u001b[0m     x_preds_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     y_preds_encoded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_preds, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x_preds[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_preds[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:134\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Labels as normalized encodings.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# transform of empty array is empty array\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1179\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;124;03m    If `y` is not a 1D array or a 2D array with a single row or column.\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[0;32m-> 1179\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    870\u001b[0m         _assert_all_finite(\n\u001b[1;32m    871\u001b[0m             array,\n\u001b[1;32m    872\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    875\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    876\u001b[0m         )\n\u001b[0;32m--> 877\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    879\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_array_api.py:68\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.astype\u001b[0;34m(self, x, dtype, copy, casting)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Honduras'"],"ename":"ValueError","evalue":"invalid literal for int() with base 10: 'Honduras'","output_type":"error"}]},{"cell_type":"code","source":"# Function to convert DePlot (predictions[0], skip_special_tokens=True) to useable data\ndef deplot_to_csv(data, filename, train=True):\n    # Split the 'data' string into separate lines\n    lines = data.split(\"<0x0A>\")\n    # print(lines)\n\n    # Remove the first line (headers)\n    header = lines[0]\n    lines = lines[2:]\n\n    # Initialize lists to store the data\n    ids = []\n    x_preds = \"\"\n    y_preds = \"\"\n    chart_types = []\n\n    id_ = filename\n    if train:\n        chart_type = predict_graph_type('/kaggle/input/benetech-making-graphs-accessible/train/images/' + filename + '.jpg')\n    else:\n        chart_type = predict_graph_type('/kaggle/input/benetech-making-graphs-accessible/test/images/' + filename + '.jpg')\n\n    ids.append(f\"{id_}_x\")\n    ids.append(f\"{id_}_y\")\n    chart_types.append(chart_type_list[chart_type])\n\n    # Process each line to extract the required information\n    x_preds = \"\"\n    y_preds = \"\"\n    for line in lines:\n        # Skip empty lines\n        if not line:\n            x_preds = \"0;0\"\n            y_preds = \"0;0\"\n            continue\n\n        # Split the line by '|' and remove leading/trailing whitespaces\n        parts = [part.strip() for part in line.split(\"|\")]\n        \n        # Skip lines where the number of parts is not equal to 2\n        if len(parts) < 2:\n            continue\n            \n        # Replace invalid values with '0'\n        x_pred = parts[0] if is_valid_value(parts[0]) else '0'\n        y_pred = parts[1] if is_valid_value(parts[1]) else '0'\n\n        # Add the values to the corresponding lists\n        if x_preds == \"\": x_preds += x_pred\n        else:x_preds += \";\" + x_pred\n\n        if y_preds == \"\": y_preds += y_pred\n        else:y_preds += \";\" + y_pred\n            \n    if x_preds == \"\":\n        x_preds = \"0;0\"\n    if y_preds == \"\":\n        y_preds = \"0;0\"\n\n    return ids, x_preds, y_preds, chart_types","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.299400Z","iopub.status.idle":"2023-06-08T01:25:01.300101Z","shell.execute_reply.started":"2023-06-08T01:25:01.299836Z","shell.execute_reply":"2023-06-08T01:25:01.299861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Create val_prediction data frame based on validation set\n# val_prediction_data = {}\n\n# for idx, (json_files, inputs, labels) in enumerate(val_dataloader):\n#     batch_size = inputs.size(0)  # Get the batch size\n#     print(\"Batch:\", idx)\n    \n#     for i in range(batch_size):\n#         json_file = json_files[i]\n#         filename = os.path.basename(json_file)\n#         filename_without_extension = os.path.splitext(filename)[0]\n        \n#         # Generate the image path by combining the image directory and the filename with the '.jpg' extension\n#         image_path = os.path.join(image_dir, filename_without_extension + '.jpg')\n#         print(image_path)\n\n#         # Test model on the image\n#         image = Image.open(image_path)\n#         inputs = processor(images=image, text=\"Generate underlying data table of the figure below:\", font_path=\"/kaggle/input/arial-font/arial.ttf\", return_tensors=\"pt\").to(device)\n#         predictions = deplot_model.generate(**inputs, max_new_tokens=512)\n#         data = processor.decode(predictions[0], skip_special_tokens=True)\n\n#         # Extract the id, x_preds, y_preds, and chart_types from the deplot_to_csv function\n#         key = filename[:-5]  # Remove the file extension from the json filename\n#         ids, x_preds, y_preds, chart_type = deplot_to_csv(data, key, train=True)\n        \n#         # Convert ';' separated string to list\n#         x_preds = x_preds.split(';')\n#         y_preds = y_preds.split(';')\n\n#         val_prediction_data[key + \"_x\"] = (x_preds, chart_type)\n#         val_prediction_data[key + \"_y\"] = (y_preds, chart_type)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.302195Z","iopub.status.idle":"2023-06-08T01:25:01.302688Z","shell.execute_reply.started":"2023-06-08T01:25:01.302432Z","shell.execute_reply":"2023-06-08T01:25:01.302469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# val_prediction = pd.DataFrame.from_dict(val_prediction_data, orient='index', columns=['data_series', 'chart_type']).rename_axis('id')\n# val_prediction.index.name = 'id'","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.304811Z","iopub.status.idle":"2023-06-08T01:25:01.305288Z","shell.execute_reply.started":"2023-06-08T01:25:01.305049Z","shell.execute_reply":"2023-06-08T01:25:01.305071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display(val_prediction)\n# print(val_prediction.index)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.307136Z","iopub.status.idle":"2023-06-08T01:25:01.308219Z","shell.execute_reply.started":"2023-06-08T01:25:01.307964Z","shell.execute_reply":"2023-06-08T01:25:01.307988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Benetech_score : \",benetech_score(val_ground_truth, val_prediction))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.310025Z","iopub.status.idle":"2023-06-08T01:25:01.310511Z","shell.execute_reply.started":"2023-06-08T01:25:01.310253Z","shell.execute_reply":"2023-06-08T01:25:01.310275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generate submission","metadata":{}},{"cell_type":"code","source":"# filename = 'c72ab56084d2.jpg'\n# test_folder = \"/kaggle/input/benetech-making-graphs-accessible/train/images/\"\n# # Create an empty DataFrame to store the results\n# all_sub_df = pd.DataFrame(columns=[\"id\", \"data_series\", \"chart_type\"])\n# # Check if the file is an image\n# if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n#     # Construct the image path\n#     image_path = os.path.join(test_folder, filename)\n\n#     # Test model on the image\n#     image = Image.open(image_path)\n#     inputs = processor(images=image, text=\"Generate underlying data table of the figure below:\", font_path=\"/kaggle/input/arial-font/arial.ttf\", return_tensors=\"pt\").to(device)\n#     predictions = deplot_model.generate(**inputs, max_new_tokens=512)\n#     data = processor.decode(predictions[0], skip_special_tokens=True)\n\n#     # Extract the id, x_preds, y_preds, and chart_types from the deplot_to_csv function\n#     file_id = os.path.splitext(filename)[0]\n#     ids, x_preds, y_preds, chart_types = deplot_to_csv(data, file_id, train=True)\n\n#     # Create the DataFrame for the current image\n#     sub_df = pd.DataFrame(\n#         data={\n#             \"id\": ids,\n#             \"data_series\": [x_preds, y_preds],\n#             \"chart_type\": chart_types * 2,\n#         }\n#     )\n#     # View df for current img\n#     show_image(image)\n#     display(sub_df)\n\n#     # Append the current DataFrame to the overall DataFrame\n#     all_sub_df = pd.concat([all_sub_df, sub_df])\n    \n# display(all_sub_df)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.312475Z","iopub.status.idle":"2023-06-08T01:25:01.312947Z","shell.execute_reply.started":"2023-06-08T01:25:01.312700Z","shell.execute_reply":"2023-06-08T01:25:01.312722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory path for the test images\ntest_folder = \"/kaggle/input/benetech-making-graphs-accessible/test/images/\"\n\n# Create an empty DataFrame to store the results\nall_sub_df = pd.DataFrame(columns=[\"id\", \"data_series\", \"chart_type\"])\n\n# Iterate through the test folder and process each image\nfor filename in os.listdir(test_folder):\n    # Check if the file is an image\n    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n        # Construct the image path\n        image_path = os.path.join(test_folder, filename)\n\n        # Test model on the image\n        image = Image.open(image_path)\n        inputs = processor(images=image, text=\"Generate underlying data table of the figure below:\", font_path=\"/kaggle/input/arial-font/arial.ttf\", return_tensors=\"pt\").to(device)\n        predictions = deplot_model.generate(**inputs, max_new_tokens=512)\n        data = processor.decode(predictions[0], skip_special_tokens=True)\n\n        # Extract the id, x_preds, y_preds, and chart_types from the deplot_to_csv function\n        file_id = os.path.splitext(filename)[0]\n        ids, x_preds, y_preds, chart_types = deplot_to_csv(data, file_id, train=False)\n\n        # Create the DataFrame for the current image\n        sub_df = pd.DataFrame(\n            data={\n                \"id\": ids,\n                \"data_series\": [x_preds, y_preds],\n                \"chart_type\": chart_types * 2,\n            }\n        )\n        # View df for current img\n        show_image(image)\n        display(sub_df)\n\n        # Append the current DataFrame to the overall DataFrame\n        all_sub_df = pd.concat([all_sub_df, sub_df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.314856Z","iopub.status.idle":"2023-06-08T01:25:01.315343Z","shell.execute_reply.started":"2023-06-08T01:25:01.315093Z","shell.execute_reply":"2023-06-08T01:25:01.315132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with column names as the first row\nheader_row = pd.DataFrame(columns=all_sub_df.columns)\nall_sub_df = pd.concat([header_row, all_sub_df], ignore_index=True)\n\n# Save the overall DataFrame to a CSV file\noutput_path = '/kaggle/working/submission.csv'\nall_sub_df.to_csv(output_path, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.317024Z","iopub.status.idle":"2023-06-08T01:25:01.317510Z","shell.execute_reply.started":"2023-06-08T01:25:01.317251Z","shell.execute_reply":"2023-06-08T01:25:01.317275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(all_sub_df)\n# print((all_sub_df[\"data_series\"][9]))\n# print(type(all_sub_df[\"id\"][0]))\n# print(type(all_sub_df[\"chart_type\"][0]))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.319411Z","iopub.status.idle":"2023-06-08T01:25:01.319897Z","shell.execute_reply.started":"2023-06-08T01:25:01.319664Z","shell.execute_reply":"2023-06-08T01:25:01.319686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSV file into a Pandas DataFrame\n# dataframe = pd.read_csv('/kaggle/input/benetech-making-graphs-accessible/sample_submission.csv')\n\n# # Display the DataFrame\n# print(dataframe)\n# # print(dataframe[\"id\"])\n# print(type(all_sub_df[\"id\"][0]))\n# print(type(dataframe[\"data_series\"][0]))\n# print(type(dataframe[\"chart_type\"][0]))","metadata":{"execution":{"iopub.status.busy":"2023-06-08T01:25:01.321800Z","iopub.status.idle":"2023-06-08T01:25:01.322254Z","shell.execute_reply.started":"2023-06-08T01:25:01.322025Z","shell.execute_reply":"2023-06-08T01:25:01.322045Z"},"trusted":true},"execution_count":null,"outputs":[]}]}